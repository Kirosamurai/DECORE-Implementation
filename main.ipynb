{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "batch_size = 64\n",
    "num_epochs = 60\n",
    "policy_training_stop_epoch = 40\n",
    "learning_rate = 0.01\n",
    "lambda_penalty = 500\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.RandomCrop(224, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
    "train_loader = data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
    "test_loader = data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "class Agent(nn.Module):\n",
    "    def __init__(self, num_channels):\n",
    "        super(Agent, self).__init__()\n",
    "        self.policy = nn.Linear(num_channels, num_channels)\n",
    "        nn.init.constant_(self.policy.bias, 6.9)\n",
    "        nn.init.constant_(self.policy.weight, 0.0)\n",
    "\n",
    "    def forward(self, state):\n",
    "        logits = self.policy(state)\n",
    "        probs = torch.sigmoid(logits)\n",
    "        return probs\n",
    "\n",
    "class PrunableConv2d(nn.Module):\n",
    "    def __init__(self, conv_layer):\n",
    "        super(PrunableConv2d, self).__init__()\n",
    "        self.conv = conv_layer\n",
    "        self.out_channels = conv_layer.out_channels\n",
    "        self.channel_mask = torch.ones(self.out_channels).to(device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv(x)\n",
    "        out = out * self.channel_mask.view(1, -1, 1, 1)\n",
    "        return out\n",
    "\n",
    "vgg16 = torchvision.models.vgg16(pretrained=True)\n",
    "\n",
    "vgg16.classifier[6] = nn.Linear(4096, 10)\n",
    "\n",
    "vgg16 = vgg16.to(device)\n",
    "\n",
    "conv_layer_indices = []\n",
    "for idx, layer in enumerate(vgg16.features):\n",
    "    if isinstance(layer, nn.Conv2d):\n",
    "        conv_layer_indices.append(idx)\n",
    "\n",
    "agents = []\n",
    "for idx in conv_layer_indices:\n",
    "    conv_layer = vgg16.features[idx]\n",
    "    prunable_conv = PrunableConv2d(conv_layer)\n",
    "    vgg16.features[idx] = prunable_conv.to(device)\n",
    "    num_channels = prunable_conv.out_channels\n",
    "    agent = Agent(num_channels).to(device)\n",
    "    agents.append(agent)\n",
    "\n",
    "def get_initial_state(num_channels):\n",
    "    return torch.ones(num_channels).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "model_optimizer = optim.SGD(vgg16.parameters(), lr=learning_rate, momentum=0.9, weight_decay=5e-4)\n",
    "\n",
    "agent_optimizers = [optim.Adam(agent.parameters(), lr=0.01) for agent in agents]\n",
    "\n",
    "def train(model, device, train_loader, optimizer, agents, agent_optimizers, epoch, lambda_penalty):\n",
    "    model.train()\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "        batch_size = inputs.size(0)\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        if agent_optimizers is not None:\n",
    "            for agent_opt in agent_optimizers:\n",
    "                agent_opt.zero_grad()\n",
    "\n",
    "        log_probs_list = []\n",
    "        entropies_list = []\n",
    "        actions_list = []\n",
    "\n",
    "        for agent, idx in zip(agents, conv_layer_indices):\n",
    "            prunable_conv = model.features[idx]\n",
    "            num_channels = prunable_conv.out_channels\n",
    "            state = get_initial_state(num_channels)\n",
    "            probs = agent(state)\n",
    "            m = torch.distributions.Bernoulli(probs)\n",
    "            actions = m.sample()\n",
    "            log_probs = m.log_prob(actions)\n",
    "            entropy = m.entropy()\n",
    "            log_probs_list.append(log_probs)\n",
    "            entropies_list.append(entropy)\n",
    "            actions_list.append(actions)\n",
    "            prunable_conv.channel_mask = actions.detach()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        classification_loss = criterion(outputs, targets)\n",
    "\n",
    "        _, predicted = outputs.max(1)\n",
    "        correct = predicted.eq(targets).sum().item()\n",
    "        total_correct += correct\n",
    "        total_samples += targets.size(0)\n",
    "\n",
    "        classification_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if agent_optimizers is not None:\n",
    "            R_acc = torch.where(predicted == targets, torch.ones(batch_size).to(device), -lambda_penalty * torch.ones(batch_size).to(device))\n",
    "            R_acc_mean = R_acc.mean()\n",
    "\n",
    "            for agent, agent_opt, log_probs, entropy, actions in zip(agents, agent_optimizers, log_probs_list, entropies_list, actions_list):\n",
    "                R_iC = torch.sum(1 - actions)\n",
    "                R_i = R_iC * R_acc_mean\n",
    "                policy_loss = -log_probs.sum() * R_i\n",
    "                entropy_loss = -0.01 * entropy.sum()\n",
    "                total_agent_loss = policy_loss + entropy_loss\n",
    "                total_agent_loss.backward()\n",
    "                agent_opt.step()\n",
    "\n",
    "        if batch_idx % 100 == 0:\n",
    "            acc = 100. * total_correct / total_samples\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Batch [{batch_idx}/{len(train_loader)}], Loss: {classification_loss.item():.4f}, Accuracy: {acc:.2f}%')\n",
    "\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in test_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader)\n",
    "    accuracy = 100. * correct / total\n",
    "    print(f'Test Loss: {test_loss:.4f}, Test Accuracy: {accuracy:.2f}%')\n",
    "    return accuracy\n",
    "\n",
    "def calculate_pruning(model, agents, threshold=0.5):\n",
    "    total_channels = 0\n",
    "    total_pruned_channels = 0\n",
    "    print(\"Pruning Summary:\")\n",
    "    for agent, idx in zip(agents, conv_layer_indices):\n",
    "        prunable_conv = model.features[idx]\n",
    "        num_channels = prunable_conv.out_channels\n",
    "        total_channels += num_channels\n",
    "        state = get_initial_state(num_channels)\n",
    "        with torch.no_grad():\n",
    "            probs = agent(state)\n",
    "        keep_channels = (probs >= threshold).cpu().numpy()\n",
    "        num_channels_to_keep = keep_channels.sum()\n",
    "        num_channels_to_drop = num_channels - num_channels_to_keep\n",
    "        total_pruned_channels += num_channels_to_drop\n",
    "        print(f'Layer {idx}: Would prune {num_channels_to_drop} channels out of {num_channels}')\n",
    "    print(f'Total channels: {total_channels}')\n",
    "    print(f'Total channels that would be pruned: {total_pruned_channels}')\n",
    "    pruned_ratio = 100.0 * total_pruned_channels / total_channels\n",
    "    print(f'Overall pruning ratio: {pruned_ratio:.2f}%')\n",
    "\n",
    "best_accuracy = 0.0\n",
    "for epoch in range(num_epochs):\n",
    "    if epoch < policy_training_stop_epoch:\n",
    "        train(vgg16, device, train_loader, model_optimizer, agents, agent_optimizers, epoch, lambda_penalty)\n",
    "    else:\n",
    "        train(vgg16, device, train_loader, model_optimizer, agents, None, epoch, lambda_penalty=0)\n",
    "    accuracy = test(vgg16, device, test_loader)\n",
    "\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        torch.save(vgg16.state_dict(), 'vgg16_cifar10_best.pth')\n",
    "\n",
    "    if epoch == policy_training_stop_epoch:\n",
    "        print(\"Calculating how many channels would be pruned based on learned policies...\")\n",
    "        calculate_pruning(vgg16, agents, threshold=0.5)\n",
    "\n",
    "torch.save(vgg16.state_dict(), 'vgg16_cifar10_final.pth')\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
